{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression Fitting - GPU\n",
    "This "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyopencl as pcl\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "\n",
      "name: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz\n",
      "device type: CPU\n",
      "global memory size:  16.0 GB\n",
      "\n",
      "##########\n",
      "\n",
      "name: Iris Pro\n",
      "device type: GPU\n",
      "global memory size:  1.5 GB\n",
      "\n",
      "##########\n",
      "\n",
      "name: AMD Radeon R9 M370X Compute Engine\n",
      "device type: GPU\n",
      "global memory size:  2.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's try to find available devices\n",
    "platforms = pcl.get_platforms()\n",
    "for p in platforms:\n",
    "    devs = p.get_devices()\n",
    "    for d in devs:\n",
    "        print(\"#\"*10)\n",
    "        print()\n",
    "        print('name:', d.name)\n",
    "        print('device type:', pcl.device_type.to_string(d.type))\n",
    "        print('global memory size: ', d.global_mem_size / (1024**3), 'GB')\n",
    "        print()\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as before set up the data\n",
    "x0_1 = ss.norm(loc=10.0, scale=2.0)\n",
    "x0_0 = ss.norm(loc=7.0, scale=2.0)\n",
    "x1_1 = ss.norm(loc=5.0, scale=3.0)\n",
    "x1_0 = ss.norm(loc=-5.0, scale=3.0)\n",
    "\n",
    "nsamps=1024\n",
    "\n",
    "X_1 = pd.DataFrame(index=range(nsamps), \n",
    "                   columns=['x0','x1', 'y'])\n",
    "X_0 = pd.DataFrame(index=range(nsamps), \n",
    "                   columns=['x0','x1', 'y'])\n",
    "\n",
    "X_1.loc[:, 'x0'] = x0_1.rvs(size=(nsamps,)).astype(np.float32)\n",
    "X_1.loc[:, 'x1'] = x1_1.rvs(size=(nsamps,)).astype(np.float32)\n",
    "X_1.loc[:, 'y'] = np.ones(shape=(nsamps,)).astype(np.float32)\n",
    "\n",
    "X_0.loc[:, 'x0'] = x0_0.rvs(size=(nsamps,)).astype(np.float32)\n",
    "X_0.loc[:, 'x1'] = x1_0.rvs(size=(nsamps,)).astype(np.float32)\n",
    "X_0.loc[:, 'y'] = np.zeros(shape=(nsamps,)).astype(np.float32)\n",
    "\n",
    "\n",
    "X_all = pd.concat((X_1, X_0), ignore_index=True)\n",
    "\n",
    "X_all = X_all.reindex(np.random.permutation(X_all.index))\n",
    "\n",
    "X = X_all.loc[:, ['x0', 'x1']]\n",
    "y = X_all.loc[:,'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to provide the path to the OpenCL file with our code\n",
    "clfile = os.path.join('..','src','glm_gpu','cl','logistic.cl')\n",
    "os.path.isfile(clfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "inline float dotproduct(__global float * a, __global float * b, const int size)\n",
      "{\n",
      "  float out = 0.0f;\n",
      "  for(int i = 0; i < size; i++){\n",
      "    out += a[i] * b[i];\n",
      "  }\n",
      "  return out;\n",
      "}\n",
      "\n",
      "inline float sigmoid(__global float * X, __global float * theta, int row_id, int nrows, int ncols)\n",
      "{\n",
      "  float linear_sum = 0.0f;\n",
      "  for(int j = 0; j < ncols; j++){\n",
      "    linear_sum += (X[row_id + j*nrows] * theta[j]);\n",
      "  }\n",
      "\n",
      "  float exponential = pow(M_E_F, -linear_sum);\n",
      "  exponential += 1.0f;\n",
      "  float sig = 1.0f / exponential;\n",
      "  return sig;\n",
      "}\n",
      "\n",
      "__kernel void matrix_row_mean(__global float * in, __global float * out, __local float * scratch, const int nrows, const int ncols)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  int lid = get_local_id(0);\n",
      "  int global_size = get_global_size(0);\n",
      "\n",
      "  // first step is a sequential loop\n",
      "  for(int j = 0; j < ncols; j++){\n",
      "    float accum = 0.0f;\n",
      "    while(gid < nrows){\n",
      "      accum += in[gid*ncols + j];\n",
      "      gid += global_size;\n",
      "    }\n",
      "    scratch[lid*ncols + j] = accum;\n",
      "  }\n",
      "\n",
      "\n",
      "  // now do a parallel reduction\n",
      "\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  for(int i = get_local_size(0)/2; i > 0; i >>=1 ){\n",
      "    if(lid < i){\n",
      "      for(int j = 0; j < ncols; j++){\n",
      "        scratch[lid*ncols + j] = scratch[lid*ncols + i*ncols + j];\n",
      "      }\n",
      "    }\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  if(lid == 0){\n",
      "    for(int j = 0; j < ncols; j++){\n",
      "      out[get_group_id(0)*ncols + j] = scratch[0*ncols + j];\n",
      "    }\n",
      "\n",
      "  }\n",
      "}\n",
      "\n",
      "/*\n",
      "* Functions here are specific to logisitic regression\n",
      "*/\n",
      "\n",
      "__kernel void sig(__global float * X, __global float * theta, __global float * out, const int nrows, const int ncols)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  out[gid] = sigmoid(X, theta, gid, nrows, ncols);\n",
      "}\n",
      "\n",
      "__kernel void logistic_cost_ols(__global float * X, __global float * theta, __global float * y, __global float * cost, const int nrows, const int ncols)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  float diff = sigmoid(X, theta,gid,nrows, ncols) - y[gid];\n",
      "  cost[gid] = powf(diff, 2.0f);\n",
      "  cost[gid] /= 2.0;\n",
      "}\n",
      "\n",
      "\n",
      "__kernel void logistic_gradient_ols(__global float * X, __global float * theta, __global float * y, __global float * gradient, const int nrows, const int ncols)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "\n",
      "  for(int j = 0; j < ncols; j++){\n",
      "    gradient[gid*ncols + j] = (y[gid] - sigmoid(X, theta, gid, nrows, ncols)) * X[gid + j*nrows];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "__kernel void logisitc_prediction(__global float * X, __global float * theta, __global float * out, const int nrows, const int ncols)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  out[gid] = sigmoid(X, theta,gid,nrows, ncols);\n",
      "}\n",
      "\n",
      "__kernel void logistic_update_ols(__global float * theta, __global float * gradient, const float learning_rate, const int nrows, const int ncols)\n",
      "{\n",
      "  for (int j = 0; j < ncols; j++){\n",
      "    theta[j] -= learning_rate * gradient[j];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYOPENCL_COMPILER_OUTPUT'] = '1'\n",
    "# here I get the device I want, which is the AMD Radeon card\n",
    "device = pcl.get_platforms()[0].get_devices()[2]\n",
    "# we create a context and attach the device to it\n",
    "cntx = pcl.Context([device])\n",
    "# and we create a queue and attach it to the context\n",
    "queue = pcl.CommandQueue(cntx)\n",
    "\n",
    "\n",
    "with open(clfile, 'r') as f:\n",
    "    # here, we read in the OpenCL code as a string and build the program\n",
    "    # all of the kernels in this file will now be stored in the 'programs' object\n",
    "    programs = pcl.Program(cntx, f.read()).build()\n",
    "    # print out the code so we can see it here\n",
    "    f.seek(0,0)\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_row_mean\n",
      "sig\n",
      "logistic_cost_ols\n",
      "logistic_gradient_ols\n",
      "logisitc_prediction\n",
      "logistic_update_ols\n"
     ]
    }
   ],
   "source": [
    "for k in programs.all_kernels():\n",
    "    print(k.function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the sake of getting this to work, I initally implemented the sum of square error as the cost function\n",
    "# I can update that with the canonical logistic regression cost function later\n",
    "def fit_gpu(X, y, theta, queue, cntx):\n",
    "    # set up some parameters we will need for each iteration\n",
    "    tol = 1e-5\n",
    "    learning_rate = 1e-2\n",
    "    nrows = np.int32(X.shape[0])\n",
    "    ncols = np.int32(X.shape[1])\n",
    "    costs = []\n",
    "    for i in range(0, 1000):\n",
    "        # here we set up the array to hold the cost values on the host.\n",
    "        # in this case, we will compute the cost of each sample individually, copy data back to the host and \n",
    "        # do the final averaging on the host\n",
    "        cost_arr = np.zeros(shape=(X.shape[0],), dtype=np.float32)\n",
    "        \n",
    "        # next let's set up the buffers between our data that is in host memory and device memory\n",
    "        X_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=X)\n",
    "        y_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=y)\n",
    "        theta_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=theta)\n",
    "        cost_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=cost_arr)\n",
    "        \n",
    "        # ok, now we set up the kernel for executing the cost function on the GPU\n",
    "        cost_event = programs.logistic_cost_ols(queue, # the queue to attach this kernel to\n",
    "                                                X.shape,# this is the global work size on the GPU. note that this is not optimal\n",
    "                                                None, # this is the local work size on the GPU. by leaving it as None, OpenCL will decide for us\n",
    "                                                X_buf, # arg 1 of the cost kernel\n",
    "                                                theta_buf, # arg 2 of the cost kernel\n",
    "                                                y_buf, # arg 3 of the cost kernel\n",
    "                                                cost_buf, # arg 4 of the cost kernel\n",
    "                                                nrows, # arg 5 of the cost kernel\n",
    "                                                ncols) # arg 6 of the cost kernel\n",
    "        \n",
    "        \n",
    "        # let's make sure it finishes executing\n",
    "        cost_event.wait()\n",
    "        # now that it's done, copy the data back to the host\n",
    "        pcl.enqueue_copy(queue, cost_arr, cost_buf)\n",
    "        # finish averaging on the host using python\n",
    "        cost_arr = cost_arr.sum()\n",
    "        cost_arr /= 2.\n",
    "        costs.append(cost_arr)\n",
    "        if cost_arr < tol:\n",
    "            break\n",
    "        else:\n",
    "            # the workflow for executing and updating the data for the gradient is similar to the above code.\n",
    "            # see if you can follow along!\n",
    "            grad_buf = pcl.Buffer(cntx, pcl.mem_flags.WRITE_ONLY , size=X.nbytes)\n",
    "            grad_event = programs.logistic_gradient_ols(queue,X.shape,None,X_buf,theta_buf,y_buf,grad_buf,nrows,ncols)\n",
    "            grad_event.wait()\n",
    "            grad_arr = np.zeros(shape=X.shape, dtype=np.float32)\n",
    "            pcl.enqueue_copy(queue, grad_arr, grad_buf)\n",
    "            grad_arr = grad_arr.mean(axis=0)\n",
    "            theta = theta + learning_rate * grad_arr\n",
    "            \n",
    "    return theta, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6)\n",
    "new_t = np.random.normal(size=theta.shape).astype(np.float32)\n",
    "fitted_t_gpu, costs_gpu = fit_gpu(X_train.values, y_train.values, new_t, queue, cntx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGDCAYAAABuj7cYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115639c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(costs_gpu)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title(\"Cost During Fitting - GPU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00917345  1.27897406]\n"
     ]
    }
   ],
   "source": [
    "print(fitted_t_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENVPy3]",
   "language": "python",
   "name": "conda-env-ENVPy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
