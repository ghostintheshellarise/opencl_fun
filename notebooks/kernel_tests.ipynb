{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz CPU 17.179869184\n",
      "Iris Pro GPU 1.610612736\n",
      "AMD Radeon R9 M370X Compute Engine GPU 2.147483648\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyopencl as pcl\n",
    "import numpy as np\n",
    "\n",
    "# let's try to find available devices\n",
    "platforms = pcl.get_platforms()\n",
    "for p in platforms:\n",
    "    devs = p.get_devices()\n",
    "    for d in devs:\n",
    "        print(d.name, pcl.device_type.to_string(d.type), d.global_mem_size / 10**9)\n",
    "\n",
    "# let's select the AMD radeon card in this case\n",
    "dev=None\n",
    "for p in pcl.get_platforms():\n",
    "    devs = p.get_devices()\n",
    "    for d in devs:\n",
    "        if pcl.device_type.to_string(d.type) == 'GPU' and (d.global_mem_size / 10**9) > 2.0:\n",
    "            dev = d\n",
    "            \n",
    "# make the opencl context\n",
    "# cntx = pcl.create_some_context()\n",
    "cntx = pcl.Context(devices=[dev])\n",
    "queue = pcl.CommandQueue(cntx, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ktest_cl_file = os.path.join('..', 'src', 'cl', 'kernel_tests.cl')\n",
    "os.path.isfile(ktest_cl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__kernel void addem(__global float * a, __global float * b, __global float * c)\n",
      "{\n",
      "\n",
      "  int i = get_global_id(0);\n",
      "  c[i] = a[i] + b[i];\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "__kernel void multiplyem(__global float * a, __global float * b, __global float * c)\n",
      "{\n",
      "  int i = get_global_id(0);\n",
      "  c[i] = a[i] * b[i];\n",
      "}\n",
      "\n",
      "__kernel void testdot(__global float * a, __global float * b, __global float * c){\n",
      "  int gid = get_global_id(0);\n",
      "  c[gid] = dot(a[gid], b[gid]);\n",
      "}\n",
      "\n",
      "__kernel void test_rowaverage(__global float * in, __global float * out, const int nrows, const int ncols)\n",
      "{\n",
      "  float nrowsf = (float) nrows;\n",
      "  for(int i = 0; i < nrows; i++){\n",
      "    for (int j = 0; j < ncols; j++){\n",
      "      out[j] += in[i * ncols + j];\n",
      "      out[j] /= nrowsf;\n",
      "    }\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "__kernel void test_reduction_avg(__global float * in, __global float * out, __local float * partial_sums, const int nrows)\n",
      "{\n",
      "  int lid = get_local_id(0);\n",
      "  int gid = get_global_id(0);\n",
      "  int group_size = get_local_size(0);\n",
      "  float nrowsf = (float) nrows;\n",
      "\n",
      "  partial_sums[lid] = in[gid];\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "  for(int i = group_size/2; i > 0; i >>= 1){\n",
      "    if(lid < i){\n",
      "      partial_sums[lid] += partial_sums[lid + i];\n",
      "    }\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  if(lid == 0){\n",
      "    out[get_group_id(0)] = partial_sums[0]/nrowsf;\n",
      "  }\n",
      "\n",
      "\n",
      "}\n",
      "\n",
      "inline void matrix_row_avg(__global float * mat, __global float * out, __local float * partial_sums, const int nrows, const int ncols)\n",
      "{\n",
      "  int lid = get_local_id(0);\n",
      "  int gid = get_global_id(0);\n",
      "  int group_size = get_local_size(0);\n",
      "  float nrowsf = (float) nrows;\n",
      "\n",
      "  for(int j = 0; j < ncols; j++){\n",
      "    partial_sums[lid*ncols + j] = mat[gid*ncols + j];\n",
      "  }\n",
      "\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  for(int i = group_size/2; i > 0; i >>= 1){\n",
      "    if(lid < i){\n",
      "      for(int j = 0; j < ncols; j++){\n",
      "        partial_sums[lid*ncols + j] += partial_sums[lid*ncols + i*ncols + j];\n",
      "      }\n",
      "    }\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  if(lid == 0){\n",
      "    for(int j = 0 ; j < ncols; j ++){\n",
      "      out[get_group_id(0) + j] = partial_sums[0 + j]/nrowsf;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "__kernel void test_reduction_avg_matrix(__global float * in_mat, __global float * out_vec, __local float * partial_sums, const int nrows, const int ncols)\n",
      "{\n",
      "  matrix_row_avg(in_mat, out_vec, partial_sums, nrows, ncols);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the kernel\n",
    "with open(ktest_cl_file, 'r') as f:\n",
    "    programs = pcl.Program(cntx, f.read()).build()\n",
    "    f.seek(0)\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the buffers and arrays\n",
    "a = np.ones(shape=(10, ), dtype=np.float32) * 3\n",
    "# b = np.ones(shape=(10, ), dtype=np.float32) * 5\n",
    "b = np.arange(0,10,1, dtype=np.float32)\n",
    "c = np.zeros(shape=(10, ), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=a)\n",
    "b_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=b)\n",
    "c_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# queue up the two kernels \n",
    "# add_event = programs.addem(queue,\n",
    "#                            a.shape,\n",
    "#                            None,\n",
    "#                            a_buf, \n",
    "#                            b_buf,\n",
    "#                            c_buf)\n",
    "\n",
    "# multiply_event = programs.multiplyem(queue,\n",
    "#                                      a.shape,\n",
    "#                                      None,\n",
    "#                                      c_buf,\n",
    "#                                      a_buf,\n",
    "#                                      b_buf)\n",
    "\n",
    "dot_event = programs.testdot(queue,\n",
    "                             a.shape,\n",
    "                             None,\n",
    "                             a_buf,\n",
    "                             b_buf,\n",
    "                             c_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# queue.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add_event.wait()\n",
    "# multiply_event.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcl.enqueue_copy(queue, b, b_buf)\n",
    "pcl.enqueue_copy(queue, c, c_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3], [4,5,6], [7,8,9]], dtype=np.float32)\n",
    "x_avg = np.zeros(shape=(X.shape[1],), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=X)\n",
    "x_avg_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=x_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_avg_event = programs.test_rowaverage(queue,\n",
    "                                         X.shape,\n",
    "                                         None,\n",
    "                                         X_buf, \n",
    "                                         x_avg_buf,\n",
    "                                         np.int32(X.shape[0]),\n",
    "                                         np.int32(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcl.enqueue_copy(queue, x_avg, x_avg_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# z = np.array([1,2,3,4,5,6,7,8,9,10], dtype=np.float32)\n",
    "z = np.random.normal(size=(2**16,)).astype(np.float32)\n",
    "z_out = np.zeros(shape=z.shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_pow2_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=z, size=z.nbytes)\n",
    "z_out_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=z_out)\n",
    "partial_buf = pcl.LocalMemory(size=z.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65536,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "clEnqueueNDRangeKernel failed: OUT_OF_RESOURCES",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-05613c46d7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                               \u001b[0mz_out_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                               \u001b[0mpartial_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                               np.int32(z.shape[0]))\n\u001b[0m",
      "\u001b[0;32m/Users/antalek/anaconda/envs/ENVPy3/lib/python3.5/site-packages/pyopencl/cffi_cl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, queue, global_size, local_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0;31m# __call__ can't be overridden directly, so we need this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;31m# trampoline hack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m     def capture_call(self, filename, queue, global_size, local_size,\n",
      "\u001b[0;32m<generated function enqueue_knl_test_reduction_avg>\u001b[0m in \u001b[0;36menqueue_knl_test_reduction_avg\u001b[0;34m(self, queue, global_size, local_size, arg0, arg1, arg2, arg3, global_offset, g_times_l, wait_for)\u001b[0m\n",
      "\u001b[0;32m/Users/antalek/anaconda/envs/ENVPy3/lib/python3.5/site-packages/pyopencl/cffi_cl.py\u001b[0m in \u001b[0;36menqueue_nd_range_kernel\u001b[0;34m(queue, kernel, global_work_size, local_work_size, global_work_offset, wait_for, g_times_l)\u001b[0m\n\u001b[1;32m   2166\u001b[0m     _handle_error(_lib.enqueue_nd_range_kernel(\n\u001b[1;32m   2167\u001b[0m         \u001b[0mptr_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwork_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_global_work_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2168\u001b[0;31m         global_work_size, local_work_size, c_wait_for, num_wait_for))\n\u001b[0m\u001b[1;32m   2169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr_event\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antalek/anaconda/envs/ENVPy3/lib/python3.5/site-packages/pyopencl/cffi_cl.py\u001b[0m in \u001b[0;36m_handle_error\u001b[0;34m(error)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;31m# }}}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: clEnqueueNDRangeKernel failed: OUT_OF_RESOURCES"
     ]
    }
   ],
   "source": [
    "reduction_event = programs.test_reduction_avg(queue,\n",
    "                                              z.shape,\n",
    "                                              None,\n",
    "                                              z_buf,\n",
    "                                              z_out_buf,\n",
    "                                              partial_buf,\n",
    "                                              np.int32(z.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcl.enqueue_copy(queue, z_out, z_out_buf).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-129.96548"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0019831159"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrows = int(2**9)\n",
    "y = np.random.normal(size = (nrows, 6), loc=10.0).astype(np.float32)\n",
    "y_row_avg = np.zeros(shape=(6,)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=y)\n",
    "y_out_buf = pcl.Buffer(cntx, pcl.mem_flags.WRITE_ONLY, size=y_row_avg.nbytes)\n",
    "partial_sum_buf = pcl.LocalMemory(size=y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_reduction_event = programs.test_reduction_avg_matrix(queue,\n",
    "                                                         y.shape,\n",
    "                                                         None,\n",
    "                                                         y_buf,\n",
    "                                                         y_out_buf,\n",
    "                                                         partial_sum_buf,\n",
    "                                                         np.int32(y.shape[0]),\n",
    "                                                         np.int32(y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_reduction_event.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.cffi_cl.NannyEvent at 0x10eb92470>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcl.enqueue_copy(queue, y_row_avg, y_out_buf, wait_for=[row_reduction_event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.97654247,  5.01037407,  5.0156889 ,  5.06041002,  4.98361921,\n",
       "        5.00504589], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_row_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  9.98460674,  10.00198746,  10.04318142,  10.05097008,\n",
       "          9.94996071,  10.02250481], dtype=float32),\n",
       " array([ 4.97654247,  5.01037407,  5.0156889 ,  5.06041002,  4.98361921,\n",
       "         5.00504589], dtype=float32))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(axis=0), y_row_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24576"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nbytes * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.98460674,  10.00198746,  10.04318142,  10.05097008,\n",
       "         9.94996071,  10.02250481], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from: https://github.com/pyopencl/pyopencl/blob/master/examples/benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of test without OpenCL:  0.13441205024719238 s\n",
      "===============================================================\n",
      "Platform name: Apple\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Apple\n",
      "Platform version: OpenCL 1.2 (Nov  1 2016 21:34:57)\n",
      "---------------------------------------------------------------\n",
      "Device name: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz\n",
      "Device type: CPU\n",
      "Device memory:  16384 MB\n",
      "Device max clock speed: 2500 MHz\n",
      "Device compute units: 8\n",
      "Device max work group size: 1024\n",
      "Device max work item sizes: [1024, 1, 1]\n",
      "Data points: 16777216\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 1\n",
      "Execution time of test: 0.0348087 s\n",
      "Results OK\n",
      "===============================================================\n",
      "Platform name: Apple\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Apple\n",
      "Platform version: OpenCL 1.2 (Nov  1 2016 21:34:57)\n",
      "---------------------------------------------------------------\n",
      "Device name: Iris Pro\n",
      "Device type: GPU\n",
      "Device memory:  1536 MB\n",
      "Device max clock speed: 1200 MHz\n",
      "Device compute units: 40\n",
      "Device max work group size: 512\n",
      "Device max work item sizes: [512, 512, 512]\n",
      "Data points: 16777216\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 32\n",
      "Execution time of test: 0.00721704 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antalek/anaconda/envs/ENVPy3/lib/python3.5/site-packages/ipykernel/__main__.py:91: DeprecationWarning: 'enqueue_read_buffer' has been deprecated in version 2011.1. Please use enqueue_copy() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results OK\n",
      "===============================================================\n",
      "Platform name: Apple\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Apple\n",
      "Platform version: OpenCL 1.2 (Nov  1 2016 21:34:57)\n",
      "---------------------------------------------------------------\n",
      "Device name: AMD Radeon R9 M370X Compute Engine\n",
      "Device type: GPU\n",
      "Device memory:  2048 MB\n",
      "Device max clock speed: 300 MHz\n",
      "Device compute units: 10\n",
      "Device max work group size: 256\n",
      "Device max work item sizes: [256, 256, 256]\n",
      "Data points: 16777216\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 64\n",
      "Execution time of test: 0.00768416 s\n",
      "Results OK\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import pyopencl as cl\n",
    "import numpy\n",
    "import numpy.linalg as la\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "data_points = 2**24 # ~8 million data points, ~32 MB data\n",
    "workers = 2**6 # 256 workers, play with this to see performance differences\n",
    "               # eg: 2**0 => 1 worker will be non-parallel execution on gpu\n",
    "               # data points must be a multiple of workers\n",
    "\n",
    "a = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "b = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "c_result = numpy.empty_like(a)\n",
    "\n",
    "# Speed in normal CPU usage\n",
    "time1 = time()\n",
    "c_temp = (a+b) # adds each element in a to its corresponding element in b\n",
    "c_temp = c_temp * c_temp # element-wise multiplication\n",
    "c_result = c_temp * (a/2.0) # element-wise half a and multiply\n",
    "time2 = time()\n",
    "\n",
    "print(\"Execution time of test without OpenCL: \", time2 - time1, \"s\")\n",
    "\n",
    "\n",
    "for platform in cl.get_platforms():\n",
    "    for device in platform.get_devices():\n",
    "        print(\"===============================================================\")\n",
    "        print(\"Platform name:\", platform.name)\n",
    "        print(\"Platform profile:\", platform.profile)\n",
    "        print(\"Platform vendor:\", platform.vendor)\n",
    "        print(\"Platform version:\", platform.version)\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(\"Device name:\", device.name)\n",
    "        print(\"Device type:\", cl.device_type.to_string(device.type))\n",
    "        print(\"Device memory: \", device.global_mem_size//1024//1024, 'MB')\n",
    "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
    "        print(\"Device compute units:\", device.max_compute_units)\n",
    "        print(\"Device max work group size:\", device.max_work_group_size)\n",
    "        print(\"Device max work item sizes:\", device.max_work_item_sizes)\n",
    "\n",
    "        # Simnple speed test\n",
    "        ctx = cl.Context([device])\n",
    "        queue = cl.CommandQueue(ctx, \n",
    "                properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "        mf = cl.mem_flags\n",
    "        a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
    "        b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b)\n",
    "        dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, b.nbytes)\n",
    "\n",
    "        prg = cl.Program(ctx, \"\"\"\n",
    "            __kernel void sum(__global const float *a,\n",
    "            __global const float *b, __global float *c)\n",
    "            {\n",
    "                        int gid = get_global_id(0);\n",
    "                        float a_temp;\n",
    "                        float b_temp;\n",
    "                        float c_temp;\n",
    "                        a_temp = a[gid]; // my a element (by global ref)\n",
    "                        b_temp = b[gid]; // my b element (by global ref)\n",
    "                        \n",
    "                        c_temp = a_temp+b_temp; // sum of my elements\n",
    "                        c_temp = c_temp * c_temp; // product of sums\n",
    "                        c_temp = c_temp * (a_temp/2.0f); // times 1/2 my a\n",
    "                        c[gid] = c_temp; // store result in global memory\n",
    "                }\n",
    "                \"\"\").build()\n",
    "\n",
    "        global_size=(data_points,)\n",
    "        local_size=(workers,)\n",
    "        preferred_multiple = cl.Kernel(prg, 'sum').get_work_group_info( \\\n",
    "            cl.kernel_work_group_info.PREFERRED_WORK_GROUP_SIZE_MULTIPLE, \\\n",
    "            device)\n",
    "\n",
    "        print(\"Data points:\", data_points)\n",
    "        print(\"Workers:\", workers)\n",
    "        print(\"Preferred work group size multiple:\", preferred_multiple)\n",
    "\n",
    "        if (workers % preferred_multiple):\n",
    "            print(\"Number of workers not a preferred multiple (%d*N).\" \\\n",
    "                    % (preferred_multiple))\n",
    "            print(\"Performance may be reduced.\")\n",
    "\n",
    "        exec_evt = prg.sum(queue, global_size, None, a_buf, b_buf, dest_buf)\n",
    "        exec_evt.wait()\n",
    "        elapsed = 1e-9*(exec_evt.profile.end - exec_evt.profile.start)\n",
    "\n",
    "        print(\"Execution time of test: %g s\" % elapsed)\n",
    "\n",
    "        c = numpy.empty_like(a)\n",
    "        cl.enqueue_read_buffer(queue, dest_buf, c).wait()\n",
    "        equal = numpy.all( c == c_result)\n",
    "\n",
    "        if not equal:\n",
    "                print(\"Results doesn't match!!\")\n",
    "        else:\n",
    "                print(\"Results OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENVPy3]",
   "language": "python",
   "name": "conda-env-ENVPy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
