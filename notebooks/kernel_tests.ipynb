{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz 2 CPU 17.179869184\n",
      "Iris Pro 4 GPU 1.610612736\n",
      "AMD Radeon R9 M370X Compute Engine 4 GPU 2.147483648\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyopencl as pcl\n",
    "import numpy as np\n",
    "\n",
    "# let's try to find available devices\n",
    "platforms = pcl.get_platforms()\n",
    "for p in platforms:\n",
    "    devs = p.get_devices()\n",
    "    for d in devs:\n",
    "        print(d.name,d.type, pcl.device_type.to_string(d.type), d.global_mem_size / 10**9)\n",
    "\n",
    "# let's select the AMD radeon card in this case\n",
    "dev=None\n",
    "for p in pcl.get_platforms():\n",
    "    devs = p.get_devices()\n",
    "    for d in devs:\n",
    "        if pcl.device_type.to_string(d.type) == 'GPU' and (d.global_mem_size / 10**9) > 2.0:\n",
    "            dev = d\n",
    "            \n",
    "# make the opencl context\n",
    "# cntx = pcl.create_some_context()\n",
    "cntx = pcl.Context( [dev])\n",
    "queue = pcl.CommandQueue(cntx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ktest_cl_file = os.path.join('..', 'src', 'cl', 'kernel_tests.cl')\n",
    "os.path.isfile(ktest_cl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__kernel void addem(__global float * a, __global float * b, __global float * c)\n",
      "{\n",
      "\n",
      "  int i = get_global_id(0);\n",
      "  c[i] = a[i] + b[i];\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "__kernel void multiplyem(__global float * a, __global float * b, __global float * c)\n",
      "{\n",
      "  int i = get_global_id(0);\n",
      "  c[i] = a[i] * b[i];\n",
      "}\n",
      "\n",
      "__kernel void testdot(__global float * a, __global float * b, __global float * c){\n",
      "  int gid = get_global_id(0);\n",
      "  c[gid] = dot(a[gid], b[gid]);\n",
      "}\n",
      "\n",
      "__kernel void test_rowaverage(__global float * in, __global float * out, const int nrows, const int ncols)\n",
      "{\n",
      "  float nrowsf = (float) nrows;\n",
      "  for(int i = 0; i < nrows; i++){\n",
      "    for (int j = 0; j < ncols; j++){\n",
      "      out[j] += in[i * ncols + j];\n",
      "      out[j] /= nrowsf;\n",
      "    }\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "__kernel void two_stage_reduce(__global float * in, __local float * scratch, __global float * out, __const int size)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  float accum = INFINITY;\n",
      "  // loop sequentially over the input\n",
      "  while(gid < size){\n",
      "    float element = in[gid];\n",
      "    accum = (accum < element) ? accum : element;\n",
      "    gid += get_global_size(0);\n",
      "  }\n",
      "\n",
      "  // now do the parallel reduction\n",
      "  int lid = get_local_id(0);\n",
      "  scratch[lid] = accum;\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  for(int i = get_local_size(0) / 2; i > 0; i >>= 1){\n",
      "    if(lid < i){\n",
      "      float other = scratch[lid + i];\n",
      "      float mine = scratch[lid];\n",
      "      scratch[lid] = (mine < other) ? mine : other;\n",
      "    }\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  if(lid == 0){\n",
      "    out[get_group_id(0)] = scratch[0];\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "__kernel void test_reduction_avg_global(__global float * in, __global float * out, __global float * partial_sums, const int nrows)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  int global_size = get_global_size(0);\n",
      "  float nrowsf = (float) nrows;\n",
      "\n",
      "  partial_sums[gid] = in[gid];\n",
      "  barrier(CLK_GLOBAL_MEM_FENCE);\n",
      "\n",
      "  for(int i = global_size/2; i > 0; i >>= 1){\n",
      "    if(gid < i){\n",
      "      partial_sums[gid] += partial_sums[gid + i];\n",
      "    }\n",
      "    barrier(CLK_GLOBAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  // if(gid == 0){\n",
      "  //   out[0] = partial_sums[0];\n",
      "  //   out[1] = (float) group_size;\n",
      "  // }\n",
      "  //\n",
      "  out[gid] = partial_sums[gid];\n",
      "\n",
      "\n",
      "}\n",
      "\n",
      "__kernel void test_reduction_avg(__global float * in, __global float * out, __local float * partial_sums, const int nrows)\n",
      "{\n",
      "  int lid = get_local_id(0);\n",
      "  int gid = get_global_id(0);\n",
      "  int group_size = get_local_size(0);\n",
      "  float nrowsf = (float) nrows;\n",
      "\n",
      "  partial_sums[lid] = in[gid];\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "  for(int i = group_size/2; i > 0; i >>= 1){\n",
      "    if(lid < i){\n",
      "      partial_sums[lid] += partial_sums[lid + i];\n",
      "    }\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  if(lid == 0){\n",
      "    out[get_group_id(0)] = partial_sums[0];\n",
      "  }\n",
      "}\n",
      "\n",
      "inline void matrix_row_avg(__global float * mat, __global float * out, __local float * partial_sums, const int nrows, const int ncols)\n",
      "{\n",
      "  int lid = get_local_id(0);\n",
      "  int gid = get_global_id(0);\n",
      "  float nrowsf = (float) nrows;\n",
      "\n",
      "  for(int j = 0; j < ncols; j++){\n",
      "    partial_sums[lid*ncols + j] = mat[gid*ncols + j];\n",
      "  }\n",
      "\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  for(int i = nrows/2; i > 0; i >>= 1){\n",
      "    if(lid < i){\n",
      "      for(int j = 0; j < ncols; j++){\n",
      "        partial_sums[lid*ncols + j] += partial_sums[lid*ncols + i*ncols + j];\n",
      "      }\n",
      "    }\n",
      "    barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  }\n",
      "\n",
      "  if(lid == 0){\n",
      "    for(int j = 0 ; j < ncols; j ++){\n",
      "      out[get_group_id(0) + j] = partial_sums[0 + j]/nrowsf;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "__kernel void test_reduction_avg_matrix(__global float * in_mat, __global float * out_vec, __local float * partial_sums, const int nrows, const int ncols)\n",
      "{\n",
      "  matrix_row_avg(in_mat, out_vec, partial_sums, nrows, ncols);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antalek/anaconda/envs/ENVPy3/lib/python3.5/site-packages/pyopencl/cffi_cl.py:1472: CompilerWarning: From-source build succeeded, but resulted in non-empty logs:\n",
      "Build on <pyopencl.Device 'AMD Radeon R9 M370X Compute Engine' on 'Apple' at 0x1021c00> succeeded, but said:\n",
      "\n",
      "<program source>:71:9: warning: unused variable 'nrowsf'\n",
      "  float nrowsf = (float) nrows;\n",
      "        ^\n",
      "<program source>:98:9: warning: unused variable 'nrowsf'\n",
      "  float nrowsf = (float) nrows;\n",
      "        ^\n",
      "\n",
      "  warn(text, CompilerWarning)\n"
     ]
    }
   ],
   "source": [
    "# build the kernel\n",
    "with open(ktest_cl_file, 'r') as f:\n",
    "    programs = pcl.Program(cntx, f.read()).build()\n",
    "    f.seek(0)\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the buffers and arrays\n",
    "a = np.ones(shape=(10, ), dtype=np.float32) * 3\n",
    "# b = np.ones(shape=(10, ), dtype=np.float32) * 5\n",
    "b = np.arange(0,10,1, dtype=np.float32)\n",
    "c = np.zeros(shape=(10, ), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=a)\n",
    "b_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=b)\n",
    "c_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# queue up the two kernels \n",
    "# add_event = programs.addem(queue,\n",
    "#                            a.shape,\n",
    "#                            None,\n",
    "#                            a_buf, \n",
    "#                            b_buf,\n",
    "#                            c_buf)\n",
    "\n",
    "# multiply_event = programs.multiplyem(queue,\n",
    "#                                      a.shape,\n",
    "#                                      None,\n",
    "#                                      c_buf,\n",
    "#                                      a_buf,\n",
    "#                                      b_buf)\n",
    "\n",
    "dot_event = programs.testdot(queue,\n",
    "                             a.shape,\n",
    "                             None,\n",
    "                             a_buf,\n",
    "                             b_buf,\n",
    "                             c_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# queue.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add_event.wait()\n",
    "# multiply_event.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcl.enqueue_copy(queue, b, b_buf)\n",
    "pcl.enqueue_copy(queue, c, c_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3], [4,5,6], [7,8,9]], dtype=np.float32)\n",
    "x_avg = np.zeros(shape=(X.shape[1],), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=X)\n",
    "x_avg_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=x_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_avg_event = programs.test_rowaverage(queue,\n",
    "                                         X.shape,\n",
    "                                         None,\n",
    "                                         X_buf, \n",
    "                                         x_avg_buf,\n",
    "                                         np.int32(X.shape[0]),\n",
    "                                         np.int32(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcl.enqueue_copy(queue, x_avg, x_avg_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Device 'AMD Radeon R9 M370X Compute Engine' on 'Apple' at 0x1021c00>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antalek/anaconda/envs/ENVPy3/lib/python3.5/site-packages/pyopencl/cffi_cl.py:1472: CompilerWarning: Built kernel retrieved from cache. Original from-source build had warnings:\n",
      "Build on <pyopencl.Device 'AMD Radeon R9 M370X Compute Engine' on 'Apple' at 0x1021c00> succeeded, but said:\n",
      "\n",
      "<program source>:82:9: warning: unused variable 'nrowsf'\n",
      "  float nrowsf = (float) nrows;\n",
      "        ^\n",
      "<program source>:109:9: warning: unused variable 'nrowsf'\n",
      "  float nrowsf = (float) nrows;\n",
      "        ^\n",
      "\n",
      "  warn(text, CompilerWarning)\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYOPENCL_COMPILER_OUTPUT'] = \"1\"\n",
    "cntx = pcl.Context( [dev])\n",
    "queue = pcl.CommandQueue(cntx, properties=pcl.command_queue_properties.PROFILING_ENABLE)\n",
    "with open(ktest_cl_file, 'r') as f:\n",
    "    programs = pcl.Program(cntx, f.read()).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# z = np.array([1,2,3,4,5,6,7,8,9,10], dtype=np.float32)\n",
    "z = np.ones(shape=(2**24,)).astype(np.float32)\n",
    "z_out = np.zeros(shape=z.shape, dtype=np.float32)\n",
    "scratch = np.zeros(shape=z.shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 1298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 1299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_pow2_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=z)\n",
    "z_out_buf = pcl.Buffer(cntx, pcl.mem_flags.WRITE_ONLY, size=z_out.nbytes)\n",
    "partial_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_WRITE | pcl.mem_flags.COPY_HOST_PTR, hostbuf=scratch)\n",
    "# partial_buf = pcl.LocalMemory(size=256*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16777216,), 16777216, 262144.0, 67108864)"
      ]
     },
     "execution_count": 1302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape, z.size, z.nbytes/256, z_out.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reduction_event = programs.test_reduction_avg_global(queue,\n",
    "#                                                       z.shape,\n",
    "#                                                       (32,),\n",
    "#                                                       z_buf,\n",
    "#                                                       z_out_buf,\n",
    "#                                                       partial_buf,\n",
    "#                                                       np.int32(z.shape[0]))\n",
    "\n",
    "# partial_buf = pcl.LocalMemory(size=256*4)\n",
    "# reduction_event = programs.test_reduction_avg(queue,\n",
    "#                                               z.shape,\n",
    "#                                               None,\n",
    "#                                               z_buf,\n",
    "#                                               z_out_buf,\n",
    "#                                               partial_buf,\n",
    "#                                               np.int32(z.shape[0]))\n",
    "\n",
    "partial_buf = pcl.LocalMemory(4*256)\n",
    "\n",
    "reduction_event = programs.two_stage_reduce(queue,\n",
    "                                            (int(z.shape[0]/2**16),),\n",
    "                                            None,\n",
    "                                            z_buf,\n",
    "                                            partial_buf,\n",
    "                                            z_out_buf,\n",
    "                                            np.int32(z.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduction_event.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcl.enqueue_copy(queue, z_out, z_out_buf).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.67772160e+07,   1.34246407e-11,   1.34246407e-11, ...,\n",
       "        -5.10447363e-14,  -5.10447363e-14,  -5.10447363e-14], dtype=float32)"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16777216.0"
      ]
     },
     "execution_count": 1307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32((z.sum())) == z_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 1289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape[0]/4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.04857600e+06,  -3.17465100e+11,  -3.17465100e+11, ...,\n",
       "        -5.10447363e-14,  -5.10447363e-14,  -5.10447363e-14], dtype=float32)"
      ]
     },
     "execution_count": 1290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096.0"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096.0"
      ]
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out.shape[0] / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(z_out == 256.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()/z_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrows = int(2**9)\n",
    "y = np.random.normal(size = (nrows, 6), loc=10.0).astype(np.float32)\n",
    "y_row_avg = np.zeros(shape=(6,)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_buf = pcl.Buffer(cntx, pcl.mem_flags.READ_ONLY | pcl.mem_flags.COPY_HOST_PTR, hostbuf=y)\n",
    "y_out_buf = pcl.Buffer(cntx, pcl.mem_flags.WRITE_ONLY, size=y_row_avg.nbytes)\n",
    "partial_sum_buf = pcl.LocalMemory(size=y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_reduction_event = programs.test_reduction_avg_matrix(queue,\n",
    "                                                         y.shape,\n",
    "                                                         None,\n",
    "                                                         y_buf,\n",
    "                                                         y_out_buf,\n",
    "                                                         partial_sum_buf,\n",
    "                                                         np.int32(y.shape[0]),\n",
    "                                                         np.int32(y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_reduction_event.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.cffi_cl.NannyEvent at 0x10eb92470>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcl.enqueue_copy(queue, y_row_avg, y_out_buf, wait_for=[row_reduction_event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.97654247,  5.01037407,  5.0156889 ,  5.06041002,  4.98361921,\n",
       "        5.00504589], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_row_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  9.98460674,  10.00198746,  10.04318142,  10.05097008,\n",
       "          9.94996071,  10.02250481], dtype=float32),\n",
       " array([ 4.97654247,  5.01037407,  5.0156889 ,  5.06041002,  4.98361921,\n",
       "         5.00504589], dtype=float32))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(axis=0), y_row_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24576"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nbytes * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.98460674,  10.00198746,  10.04318142,  10.05097008,\n",
       "         9.94996071,  10.02250481], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from: https://github.com/pyopencl/pyopencl/blob/master/examples/benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of test without OpenCL:  0.15439105033874512 s\n",
      "===============================================================\n",
      "Platform name: Apple\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Apple\n",
      "Platform version: OpenCL 1.2 (Nov  1 2016 21:34:57)\n",
      "---------------------------------------------------------------\n",
      "Device name: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz\n",
      "Device type: CPU\n",
      "Device memory:  16 GB\n",
      "Device max clock speed: 2500 MHz\n",
      "Device compute units: 8\n",
      "Device max work group size: 1024\n",
      "Device max work item sizes: [1024, 1, 1]\n",
      "Data points: 16777216\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 1\n",
      "Execution time of test: 0.0351943 s\n",
      "Results OK\n",
      "===============================================================\n",
      "Platform name: Apple\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Apple\n",
      "Platform version: OpenCL 1.2 (Nov  1 2016 21:34:57)\n",
      "---------------------------------------------------------------\n",
      "Device name: Iris Pro\n",
      "Device type: GPU\n",
      "Device memory:  1 GB\n",
      "Device max clock speed: 1200 MHz\n",
      "Device compute units: 40\n",
      "Device max work group size: 512\n",
      "Device max work item sizes: [512, 512, 512]\n",
      "Data points: 16777216\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 32\n",
      "Execution time of test: 0.00827464 s\n",
      "Results OK\n",
      "===============================================================\n",
      "Platform name: Apple\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Apple\n",
      "Platform version: OpenCL 1.2 (Nov  1 2016 21:34:57)\n",
      "---------------------------------------------------------------\n",
      "Device name: AMD Radeon R9 M370X Compute Engine\n",
      "Device type: GPU\n",
      "Device memory:  2 GB\n",
      "Device max clock speed: 300 MHz\n",
      "Device compute units: 10\n",
      "Device max work group size: 256\n",
      "Device max work item sizes: [256, 256, 256]\n",
      "Data points: 16777216\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 64\n",
      "Execution time of test: 0.0076963 s\n",
      "Results OK\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import pyopencl as cl\n",
    "import numpy\n",
    "import numpy.linalg as la\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "data_points = 2**24 # ~8 million data points, ~32 MB data\n",
    "workers = 2**6 # 256 workers, play with this to see performance differences\n",
    "               # eg: 2**0 => 1 worker will be non-parallel execution on gpu\n",
    "               # data points must be a multiple of workers\n",
    "\n",
    "a = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "b = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "c_result = numpy.empty_like(a)\n",
    "\n",
    "# Speed in normal CPU usage\n",
    "time1 = time()\n",
    "c_temp = (a+b) # adds each element in a to its corresponding element in b\n",
    "c_temp = c_temp * c_temp # element-wise multiplication\n",
    "c_result = c_temp * (a/2.0) # element-wise half a and multiply\n",
    "time2 = time()\n",
    "\n",
    "print(\"Execution time of test without OpenCL: \", time2 - time1, \"s\")\n",
    "\n",
    "\n",
    "for platform in cl.get_platforms():\n",
    "    for device in platform.get_devices():\n",
    "        print(\"===============================================================\")\n",
    "        print(\"Platform name:\", platform.name)\n",
    "        print(\"Platform profile:\", platform.profile)\n",
    "        print(\"Platform vendor:\", platform.vendor)\n",
    "        print(\"Platform version:\", platform.version)\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(\"Device name:\", device.name)\n",
    "        print(\"Device type:\", cl.device_type.to_string(device.type))\n",
    "        print(\"Device memory: \", device.global_mem_size//1024//1024//1024, 'GB')\n",
    "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
    "        print(\"Device compute units:\", device.max_compute_units)\n",
    "        print(\"Device max work group size:\", device.max_work_group_size)\n",
    "        print(\"Device max work item sizes:\", device.max_work_item_sizes)\n",
    "\n",
    "        # Simnple speed test\n",
    "        ctx = cl.Context([device])\n",
    "        queue = cl.CommandQueue(ctx, \n",
    "                properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "        mf = cl.mem_flags\n",
    "        a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
    "        b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b)\n",
    "        dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, b.nbytes)\n",
    "\n",
    "        prg = cl.Program(ctx, \"\"\"\n",
    "            __kernel void sum(__global float *a,\n",
    "            __global float *b, __global float *c)\n",
    "            {\n",
    "                        int gid = get_global_id(0);\n",
    "                        float a_temp;\n",
    "                        float b_temp;\n",
    "                        float c_temp;\n",
    "                        a_temp = a[gid]; // my a element (by global ref)\n",
    "                        b_temp = b[gid]; // my b element (by global ref)\n",
    "                        \n",
    "                        c_temp = a_temp+b_temp; // sum of my elements\n",
    "                        c_temp = c_temp * c_temp; // product of sums\n",
    "                        c_temp = c_temp * (a_temp/2.0f); // times 1/2 my a\n",
    "                        c[gid] = c_temp; // store result in global memory\n",
    "                }\n",
    "                \"\"\").build()\n",
    "\n",
    "        global_size=(data_points,1)\n",
    "        local_size=(workers,)\n",
    "        preferred_multiple = cl.Kernel(prg, 'sum').get_work_group_info( \\\n",
    "            cl.kernel_work_group_info.PREFERRED_WORK_GROUP_SIZE_MULTIPLE, \\\n",
    "            device)\n",
    "\n",
    "        print(\"Data points:\", data_points)\n",
    "        print(\"Workers:\", workers)\n",
    "        print(\"Preferred work group size multiple:\", preferred_multiple)\n",
    "\n",
    "        if (workers % preferred_multiple):\n",
    "            print(\"Number of workers not a preferred multiple (%d*N).\" \\\n",
    "                    % (preferred_multiple))\n",
    "            print(\"Performance may be reduced.\")\n",
    "\n",
    "        exec_evt = prg.sum(queue, global_size, None, a_buf, b_buf, dest_buf)\n",
    "        exec_evt.wait()\n",
    "        elapsed = 1e-9*(exec_evt.profile.end - exec_evt.profile.start)\n",
    "\n",
    "        print(\"Execution time of test: %g s\" % elapsed)\n",
    "\n",
    "        c = numpy.empty_like(a)\n",
    "        cl.enqueue_copy(queue, c, dest_buf).wait()\n",
    "        equal = numpy.all( c == c_result)\n",
    "\n",
    "        if not equal:\n",
    "                print(\"Results doesn't match!!\")\n",
    "        else:\n",
    "                print(\"Results OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENVPy3]",
   "language": "python",
   "name": "conda-env-ENVPy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
